"""Create documents table

Revision ID: e740d970a15b
Revises: 
Create Date: 2025-11-04 11:15:29.817574

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy import Text
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'e740d970a15b'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('documents',
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique document identifier'),
    sa.Column('source_id', sa.UUID(), nullable=False, comment='Source/collection identifier'),
    sa.Column('content', sa.Text(), nullable=True, comment='Original raw content'),
    sa.Column('extracted_text', sa.Text(), nullable=True, comment='Extracted text content'),
    sa.Column('structured_content', postgresql.JSONB(astext_type=Text()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='Structured content as JSON'),
    sa.Column('embeddings', sa.ARRAY(sa.Float()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='Document embeddings (768 dimensions)'),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=False, comment='Creation timestamp'),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=False, comment='Last update timestamp'),
    sa.Column('last_processed_at', sa.DateTime(timezone=True), nullable=True, comment='Last processing timestamp'),
    sa.Column('processing_attempts', sa.Integer(), nullable=False, comment='Number of processing attempts'),
    sa.Column('processing_duration', sa.Float(), nullable=True, comment='Last processing duration in seconds'),
    sa.Column('predicted_categories', sa.ARRAY(sa.String()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='ML-predicted categories'),
    sa.Column('category_confidence', sa.Float(), nullable=True, comment='Category prediction confidence (0-1)'),
    sa.Column('manual_categories', sa.ARRAY(sa.String()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='Manually assigned categories'),
    sa.Column('quality_metrics', postgresql.JSONB(astext_type=Text()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='Data quality metrics as JSON'),
    sa.Column('validation_errors', sa.ARRAY(sa.Text()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='Validation errors (last 20)'),
    sa.Column('chunks', postgresql.JSONB(astext_type=Text()).with_variant(sa.JSON(), 'sqlite'), nullable=True, comment='Document chunks as JSON array'),
    sa.Column('chunk_count', sa.Integer(), nullable=False, comment='Number of chunks'),
    sa.Column('version', sa.Integer(), nullable=False, comment='Document version number'),
    sa.Column('checksum', sa.String(length=64), nullable=True, comment='Content checksum for integrity'),
    sa.Column('document_metadata', postgresql.JSONB(astext_type=Text()).with_variant(sa.JSON(), 'sqlite'), nullable=False, comment='Document metadata (file info, status, etc.)'),
    sa.CheckConstraint('category_confidence IS NULL OR (category_confidence >= 0 AND category_confidence <= 1)', name='check_category_confidence_range'),
    sa.CheckConstraint('chunk_count >= 0', name='check_chunk_count_non_negative'),
    sa.CheckConstraint('processing_attempts >= 0', name='check_processing_attempts_non_negative'),
    sa.PrimaryKeyConstraint('id'),
    comment='Persistent storage for Document entities'
    )
    op.create_index('idx_documents_chunk_count', 'documents', ['chunk_count'], unique=False)
    op.create_index('idx_documents_created_at', 'documents', [sa.literal_column('created_at DESC')], unique=False)
    op.create_index('idx_documents_source_id', 'documents', ['source_id'], unique=False)
    op.create_index(op.f('ix_documents_source_id'), 'documents', ['source_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_documents_source_id'), table_name='documents')
    op.drop_index('idx_documents_source_id', table_name='documents')
    op.drop_index('idx_documents_created_at', table_name='documents')
    op.drop_index('idx_documents_chunk_count', table_name='documents')
    op.drop_table('documents')
    # ### end Alembic commands ###
